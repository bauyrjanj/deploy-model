{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:  Import some libraries and define a few environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-west-2 region. You will use the 433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "role = get_execution_role() # Get the execution role for the notebook instance\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the relevant container in your region\n",
    "from sagemaker import image_uris\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", my_region, \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-west-2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::080038477882:role/service-role/AmazonSageMaker-ExecutionRole-20201213T225971\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-west-2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: In this step, create an S3 bucket that will store your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'bauka-s3-ml-pipeline' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Download the data to your Amazon SageMaker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "  print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "  print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "  model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>y_no</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  campaign  pdays  previous  no_previous_contact  not_working  \\\n",
       "0   56         1    999         0                    1            0   \n",
       "1   57         1    999         0                    1            0   \n",
       "2   37         1    999         0                    1            0   \n",
       "3   40         1    999         0                    1            0   \n",
       "4   56         1    999         0                    1            0   \n",
       "\n",
       "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  ...  \\\n",
       "0           0                0                 0              1  ...   \n",
       "1           0                0                 0              0  ...   \n",
       "2           0                0                 0              0  ...   \n",
       "3           1                0                 0              0  ...   \n",
       "4           0                0                 0              0  ...   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                1                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                1                0                0   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \\\n",
       "0                0                 0                     1                 0   \n",
       "1                0                 0                     1                 0   \n",
       "2                0                 0                     1                 0   \n",
       "3                0                 0                     1                 0   \n",
       "4                0                 0                     1                 0   \n",
       "\n",
       "   y_no  y_yes  \n",
       "0     1      0  \n",
       "1     1      0  \n",
       "2     1      0  \n",
       "3     1      0  \n",
       "4     1      0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41188 entries, 0 to 41187\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype\n",
      "---  ------                         --------------  -----\n",
      " 0   age                            41188 non-null  int64\n",
      " 1   campaign                       41188 non-null  int64\n",
      " 2   pdays                          41188 non-null  int64\n",
      " 3   previous                       41188 non-null  int64\n",
      " 4   no_previous_contact            41188 non-null  int64\n",
      " 5   not_working                    41188 non-null  int64\n",
      " 6   job_admin.                     41188 non-null  int64\n",
      " 7   job_blue-collar                41188 non-null  int64\n",
      " 8   job_entrepreneur               41188 non-null  int64\n",
      " 9   job_housemaid                  41188 non-null  int64\n",
      " 10  job_management                 41188 non-null  int64\n",
      " 11  job_retired                    41188 non-null  int64\n",
      " 12  job_self-employed              41188 non-null  int64\n",
      " 13  job_services                   41188 non-null  int64\n",
      " 14  job_student                    41188 non-null  int64\n",
      " 15  job_technician                 41188 non-null  int64\n",
      " 16  job_unemployed                 41188 non-null  int64\n",
      " 17  job_unknown                    41188 non-null  int64\n",
      " 18  marital_divorced               41188 non-null  int64\n",
      " 19  marital_married                41188 non-null  int64\n",
      " 20  marital_single                 41188 non-null  int64\n",
      " 21  marital_unknown                41188 non-null  int64\n",
      " 22  education_basic.4y             41188 non-null  int64\n",
      " 23  education_basic.6y             41188 non-null  int64\n",
      " 24  education_basic.9y             41188 non-null  int64\n",
      " 25  education_high.school          41188 non-null  int64\n",
      " 26  education_illiterate           41188 non-null  int64\n",
      " 27  education_professional.course  41188 non-null  int64\n",
      " 28  education_university.degree    41188 non-null  int64\n",
      " 29  education_unknown              41188 non-null  int64\n",
      " 30  default_no                     41188 non-null  int64\n",
      " 31  default_unknown                41188 non-null  int64\n",
      " 32  default_yes                    41188 non-null  int64\n",
      " 33  housing_no                     41188 non-null  int64\n",
      " 34  housing_unknown                41188 non-null  int64\n",
      " 35  housing_yes                    41188 non-null  int64\n",
      " 36  loan_no                        41188 non-null  int64\n",
      " 37  loan_unknown                   41188 non-null  int64\n",
      " 38  loan_yes                       41188 non-null  int64\n",
      " 39  contact_cellular               41188 non-null  int64\n",
      " 40  contact_telephone              41188 non-null  int64\n",
      " 41  month_apr                      41188 non-null  int64\n",
      " 42  month_aug                      41188 non-null  int64\n",
      " 43  month_dec                      41188 non-null  int64\n",
      " 44  month_jul                      41188 non-null  int64\n",
      " 45  month_jun                      41188 non-null  int64\n",
      " 46  month_mar                      41188 non-null  int64\n",
      " 47  month_may                      41188 non-null  int64\n",
      " 48  month_nov                      41188 non-null  int64\n",
      " 49  month_oct                      41188 non-null  int64\n",
      " 50  month_sep                      41188 non-null  int64\n",
      " 51  day_of_week_fri                41188 non-null  int64\n",
      " 52  day_of_week_mon                41188 non-null  int64\n",
      " 53  day_of_week_thu                41188 non-null  int64\n",
      " 54  day_of_week_tue                41188 non-null  int64\n",
      " 55  day_of_week_wed                41188 non-null  int64\n",
      " 56  poutcome_failure               41188 non-null  int64\n",
      " 57  poutcome_nonexistent           41188 non-null  int64\n",
      " 58  poutcome_success               41188 non-null  int64\n",
      " 59  y_no                           41188 non-null  int64\n",
      " 60  y_yes                          41188 non-null  int64\n",
      "dtypes: int64(61)\n",
      "memory usage: 19.5 MB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "shuffled = model_data.sample(frac=1, random_state=1729) # shuffle the dataset \n",
    "train_data, test_data = np.split(shuffled, [int(0.7 * len(model_data))]) # split the data into 70% training and 30% test sets\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train the model from the data\n",
    "\n",
    "To use an Amazon SageMaker pre-built XGBoost model, you will need to reformat the header and first column of the training data and load the data from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data and load the data from the S3 bucket\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pre-built XGBoost model - using XGBoost as a built-in algorithm not a framework!!!\n",
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[my_region],role, instance_count=1, instance_type='ml.m4.xlarge',output_path='s3://{}/{}/output'.format(bucket_name, prefix),sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='binary:logistic',num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 18:22:44 Starting - Starting the training job...\n",
      "2020-12-14 18:23:08 Starting - Launching requested ML instancesProfilerReport-1607970164: InProgress\n",
      "......\n",
      "2020-12-14 18:24:09 Starting - Preparing the instances for training......\n",
      "2020-12-14 18:25:10 Downloading - Downloading input data...\n",
      "2020-12-14 18:25:39 Training - Downloading the training image...\n",
      "2020-12-14 18:26:13 Uploading - Uploading generated training model\n",
      "2020-12-14 18:26:13 Completed - Training job completed\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-12-14:18:26:00:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-12-14:18:26:00:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2020-12-14:18:26:00:INFO] File size need to be processed in the node: 3.38mb. Available memory size in the node: 8421.46mb\u001b[0m\n",
      "\u001b[34m[2020-12-14:18:26:00:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[18:26:00] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[18:26:00] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.100482\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.099858\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.099476\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.099025\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.099476\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.099372\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.09906\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.099025\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.099164\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.098852\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.098574\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.098609\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.098297\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.098054\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.098158\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.098124\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.098124\u001b[0m\n",
      "\u001b[34m[18:26:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.097881\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.097777\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.097742\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.097707\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.097291\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.097256\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.097256\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.097187\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.097118\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09691\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.096771\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.096806\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.096806\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.096459\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.096424\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.096563\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.096597\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[18:26:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.096112\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.096147\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.096112\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 30 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.096147\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.096216\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.096181\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 28 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.095869\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[18:26:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.0958\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.09573\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.095765\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.095592\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.095557\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 26 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.095557\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 30 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.095106\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.095106\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 24 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.095279\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.094828\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 22 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.094863\u001b[0m\n",
      "\u001b[34m[18:26:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.094759\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 64\n",
      "Billable seconds: 64\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the data\n",
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model on a server and create an endpoint you can access\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.5%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    90% (10785)    35% (151)\n",
      "Purchase        10% (1143)     65% (278) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Terminate your resources (Avoid Costs!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '7F28EC3056F37522',\n",
       "   'HostId': 'd/nL17rdCdn6rsjgknUR4gfway8UEpHjcV9mmia0wKdO+JkPee37saF+a4aSrKSysczBR8qwUj8=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'd/nL17rdCdn6rsjgknUR4gfway8UEpHjcV9mmia0wKdO+JkPee37saF+a4aSrKSysczBR8qwUj8=',\n",
       "    'x-amz-request-id': '7F28EC3056F37522',\n",
       "    'date': 'Mon, 14 Dec 2020 18:49:04 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/profiler-output/system/incremental/2020121418/1607970300.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/profiler-output/system/incremental/2020121418/1607970360.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-12-14-18-22-44-660/rule-output/ProfilerReport-1607970164/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/train/train.csv'}]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use XGBoost as a Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"verbose\":\"1\",\n",
    "        \"objective\":\"reg:linear\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'DEMO-xgboost-as-a-framework'\n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'abalone-xgb-framework')\n",
    "\n",
    "# construct a SageMaker XGBoost estimator\n",
    "# specify the entry_point to your xgboost training script\n",
    "estimator = XGBoost(entry_point = \"your_xgboost_abalone_script.py\", \n",
    "                    framework_version='1.2-1',\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    role=sagemaker.get_execution_role(),\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    output_path=output_path)\n",
    "\n",
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"libsvm\"\n",
    "train_input = TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'train'), content_type=content_type)\n",
    "validation_input = TrainingInput(\"s3://{}/{}/{}/\".format(bucket, prefix, 'validation'), content_type=content_type)\n",
    "\n",
    "# execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
